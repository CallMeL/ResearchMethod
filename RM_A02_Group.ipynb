{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CallMeL/ResearchMethod/blob/master/RM_A02_Group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANIfGSOOB0M_"
      },
      "source": [
        "# Research Methods <br>UHH - Knowledge Technology Research Group - WiSe 2023/2024\n",
        "## Assignment #2 - Empirical Studies & EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDVNJkYkB0NE"
      },
      "source": [
        "***\n",
        "### Group:\n",
        "### Names of members:\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdFh7MDB0NF"
      },
      "source": [
        "### Instructions:\n",
        "\n",
        "Please answer the questions below. Copy this notebook and enter your answers underneath each task description, inserting cells as needed. You may use a combination of [python 3](https://www.python.org), [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), and [LaTex](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) to formulate your responses. In order to successfully complete the assignment, you will need the lecture material provided in the [RM moodle course](https://lernen.min.uni-hamburg.de/course/view.php?id=3416), especially L02 & L03.\n",
        "\n",
        "**Make sure to use only a copy of this notebook for your answers instead of a new/blank notebook.**\n",
        "\n",
        "### Grading Criteria:\n",
        "\n",
        "In order to successfully pass this assignment, you will need **at least a total of 70 points out of 100 points**, and every task has to be tackled.\n",
        "\n",
        "### Submission:\n",
        "\n",
        "Please upload the following two files **until Tuesday, November 7, 2023, 20:00 CET (Germany)** together in a .zip archive in moodle:\n",
        "1. a (single) copy of this jupyter notebook containing your answers for all tasks (file extension: .ipynb)\n",
        "2. an [exported PDF document](https://jupyterlab.readthedocs.io/en/stable/user/export.html) of the jupyter notebook (file extension: .pdf)\n",
        "\n",
        "### Presentation:\n",
        "\n",
        "Make sure that each (!) group member takes part in solving this assignment and is prepared to answer questions and/or present solutions from your submitted notebook during our assignment revision meeting scheduled for **Wednesday, November 15, 2023, 10:00 - 13:00 CET (Germany)**.\n",
        "\n",
        "### File Naming:\n",
        "\n",
        "Add the group letter to the file name prior to submission. For example, if your group letter is \"A\" (see group selection in moodle), you would use the following filename:\n",
        "1. RM_A02_Group_A.ipynb\n",
        "2. RM_A02_Group_A.pdf\n",
        "\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpNlyytnB0NG"
      },
      "source": [
        "#### Task 1 **[10 points] Data Scales**\n",
        "\n",
        "1. For each of the features in the CRU dataset (e.g., precipitation), identify all scales of data whose definition is valid for all entries in the columns that belong to that feature. Create a table using python code that contains all features as rows, data scales as columns, and binary table entries indicating whether the feature values (i.e., column entries in the database) correspond to the data scale or not.\n",
        "2. For each of the features, briefly explain to which of the errors mentioned in the lecture this feature is prone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiTfW39cB0NH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RLaNOgtB0NJ"
      },
      "source": [
        "#### Task 2 **[10 points] Types of Experiments**\n",
        "\n",
        "Different types of studies and experiments were discussed in the lecture. With respect to climate data, state whether it is possible to conduct the following experiments given below. Briefly explain your reasoning and give an example for each of the four types.\n",
        "\n",
        "1. Exploratory study\n",
        "2. Assessment study\n",
        "3. Observation experiments\n",
        "4. Manipulation experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpPKZKeCB0NJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuPzGHP3B0NK"
      },
      "source": [
        "#### Task 3 **[40 points] Visualization**\n",
        "\n",
        "Plot the four statistics given below using suitable python packages:\n",
        "\n",
        "1. Timeline of cumulative precipitation over the course of the year 2022. _(i)_ world-wide and _(ii)_ per country.\n",
        "2. Average precipitation per wetday per country in 2022.\n",
        "3. Climate diagram based on the average data from the last decade (2013 - 2022) for one country of your choice.<br> _Note: Include the amount of precipitation as well as min, mean, and max temperature._\n",
        "4. Frequency distribution of mean temperatures in Germany in the timespans (i) 1963-1982 and (ii) 2003-2022. <br> _Note: Use appropriate, common bins for both diagrams._\n",
        "\n",
        "As a reminder, the following instructions will apply to **all visualization tasks** as part of the RM course: Make sure to use appropriate plot types for visualization (e.g., histogram, bar plot, scatter plot, line plot, ...) and proper axis labeling/scaling. Add a legend to each plot to facilitate the viewer's understanding. Make sure to describe/interpret the outcome of your visualization.\n",
        "\n",
        "_Hint: It might be helpful to use the [wide__to__long](https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html) function in pandas to format the data for plotting!_ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-7O2cV2B0NK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JuFZHz0B0NL"
      },
      "source": [
        "#### Task 4 **[40 points] EDA**\n",
        "\n",
        "Following the Titanic example from the lecture, we want to gain first insights into multivariate EDA. We want to see if the climate warming is different between countries. For this purpose, take the following steps using python to answer the question **whether the number of warmer/colder months (compared to 50 years ago) changes between countries and whether there is a difference between decades.**\n",
        "\n",
        "For this task use the data from Nigeria and Portugal starting from the year 1963.\n",
        "\n",
        "1. For each month, calculate if it was warmer or colder compared to the same month 50 years ago (e.g., you compare 01/1963 with 01/1913, then 02/1963 with 02/1913, ...).\n",
        "2. Create two contingency tables of **total number of warmer and colder months per country** (one containing the absolute counts and the second one containing row and column proportions).\n",
        "3. Create another two contingency tables of **total number of warmer and colder months per decade** (one containing the absolute counts and the second one containing row and column proportions).\n",
        "4. Plot a histogram or bar chart that shows the **total number of warmer months by country and decade**.\n",
        "   _Hint: The usage of different colors might help a lot!_\n",
        "6. Now combine the contingency tables of task 4.2 and 4.3 (see Titanic example discussed in the EDA lecture), so that you have a subdivision into countries by decade, with absolute counts and row/column proportions.\n",
        "7. Calculate the expected frequencies $f_e$ for each conjunct event in the contingency table from task 4.5 and create a copy of the table from task 4.5 containing the $f_e$ values.\n",
        "8. Calculate $\\chi²_{Nigeria}$ and $\\chi²_{Portugal}$ and interpret.\n",
        "9. What does a small $\\chi²$ value mean? What if it's zero? Explain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDRaqOigB0NM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}